{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import env\n",
    "import wrangle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# modeling methods\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression \n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_zillow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle.split_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2fcc154d4d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/zillow_project_2021/Caitlyn/wrangle.py\u001b[0m in \u001b[0;36mprep_longitude_latitude_houseage_clusters\u001b[0;34m(some_dataframe)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0msome_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_cluster_longitude_latitude_houseage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0msome_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dummy_longitude_latitude_houseage_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msome_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/zillow_project_2021/Caitlyn/wrangle.py\u001b[0m in \u001b[0;36mpredict_cluster_longitude_latitude_houseage\u001b[0;34m(some_dataframe)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cluster_longitude_latitude_houseage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0msome_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude_latitude_houseage_cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msome_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "train = wrangle.prep_longitude_latitude_houseage_clusters(train)\n",
    "validate = wrangle.prep_longitude_latitude_houseage_clusters(validate)\n",
    "test = wrangle.prep_longitude_latitude_houseage_clusters(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm, 1)\n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='limegreen', label='Line of Regrssion', linewidth=5)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"yellow\", label='Baseline', linewidth=5)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='The Ideal Line: Predicted = Actual', linewidth=5)\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm-y_validate.logerror, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.axhline(label=\"No Error\", color='black', linewidth=7)\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 5, figsize=(8,16), sharey=True)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.title(\"Comparing the Distribution of logerrors to Distributions of Predicted logerrors Linear Regression Models\")\n",
    "plt.xlabel(\"logerror\", size = 15)\n",
    "plt.ylabel(\"logerror Count\", size = 15)\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(y_validate.logerror, color='cyan', alpha=.5,  ec='black')\n",
    "plt.title('Actual logerrors', size=15)\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(y_validate.logerror_pred_lm, color='lawngreen', alpha=.5,  ec='black')\n",
    "plt.title('Model: LinearRegression', size=15)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(y_validate.logerror, color='lawngreen', alpha=.5, label=\"Actual Final logerrors\", ec='black')\n",
    "plt.hist(y_validate.logerror_pred_lm, color='cyan', alpha=.5, label=\"Model: LinearRegression\", ec='black')\n",
    "plt.title(\"All Graphs Stacked\", size=15)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "lm.fit(X_test, y_test.logerror)\n",
    "y_test['logerror_pred_lm'] = lm.predict(X_test)\n",
    "rmse_test_lm = mean_squared_error(y_test.logerror, y_test.logerror_pred_lm)**(1/2)\n",
    "print(\"RMSE for OLS using LinearRegression Test Data: \", rmse_test_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_baseline = r2_score(y_validate.logerror, y_validate.logerror_pred_median)\n",
    "r2_score_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_ols = r2_score(y_validate.logerror, y_validate.logerror_pred_lm)\n",
    "r2_score_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = wrangle.split_train_validate_test(train, validate, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "    # turn it into a single pandas dataframe\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "    # wrap them as dataframes\n",
    "\n",
    "# 1. Predict logerror_pred_mean\n",
    "    # 2 different aselines of mean and medium\n",
    "logerror_pred_mean = y_train['logerror'].mean()\n",
    "y_train['logerror_pred_mean'] = logerror_pred_mean\n",
    "y_validate['logerror_pred_mean'] = logerror_pred_mean\n",
    "\n",
    "# 2. compute logerror_pred_median\n",
    "    # same process as mean (above)\n",
    "logerror_pred_median = y_train['logerror'].median()\n",
    "y_train['logerror_pred_median'] = logerror_pred_median\n",
    "y_validate['logerror_pred_median'] = logerror_pred_median\n",
    "\n",
    "# 3. RMSE of logerror_pred_mean\n",
    "rmse_train_mean = mean_squared_error(y_train.logerror, \n",
    "                                     y_train.logerror_pred_mean)**(1/2)\n",
    "    # stick with root mean square error\n",
    "        # not your only option but that is what we will be using here\n",
    "            # just because it is eaiest to us and explain\n",
    "    # remember when you call you it will be your y_true and y_pred\n",
    "rmse_validate_mean = mean_squared_error(y_validate.logerror, \n",
    "                                        y_validate.logerror_pred_mean)**(1/2)\n",
    "    # do the same thing for the validate set as done above for the train set\n",
    "    \n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 2))\n",
    "print(' ')\n",
    "# 4. RMSE of logerror_pred_median\n",
    "rmse_train_medium = mean_squared_error(y_train.logerror, \n",
    "                                       y_train.logerror_pred_median)**(1/2)\n",
    "\n",
    "rmse_validate_medium = mean_squared_error(y_validate.logerror, \n",
    "                                          y_validate.logerror_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_medium, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_medium, 2))\n",
    "\n",
    "# median comes out a little higher than mean \n",
    "    # but a little lower than our validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train, y_train.logerror)\n",
    "    # just call y_train.actual_target\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm'] = lm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm)**(1/2)\n",
    "    # make sure you are using x_validate an not x_train\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train_lm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"blue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1.0)\n",
    "    # what alpha is in this case\n",
    "        # kidn of that regualizer that make lasso a little bit different\n",
    "        # can go from 0 to infinity\n",
    "            # it will eventually stop changing the efficivicy of you model \n",
    "                # depenind on th enumber of features being fed in\n",
    "            # if alpha = 0 it is the same thing as a los model\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train, y_train.logerror)\n",
    "    # fit the thing\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lars = median_squared_error(y_train.logerror, y_train.logerror_pred_lars)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lars = median_squared_error(y_validate.logerror, y_validate.logerror_pred_lars)**1/2\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train_lars, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"darkred\", s=100, label=\"Model: LinearRegression\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Final Grade\")\n",
    "plt.ylabel(\"Predicted Final Grade\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_glm = mean_squared_error(y_train.logerror, y_train.logerror_pred_glm)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_glm = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_glm)**1/2\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train_glm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_mean, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"darkviolet\", s=100, label=\"Model: TweedieRegressor\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate)\n",
    "    # dont call fit transform just call transform\n",
    "        # we only fit train not validate\n",
    "X_test_degree2 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm2 = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm2)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm2 = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm2)**1/2\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm2, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm2, \n",
    "            alpha=.5, color=\"darkturquoise\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf3 = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf3.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf3.transform(X_validate)\n",
    "    # dont call fit transform just call transform\n",
    "        # we only fit train not validate\n",
    "X_test_degree3 = pf3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm3.fit(X_train_degree3, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm3'] = lm3.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm3 = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm2)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm3'] = lm3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm3 = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm2)**1/2\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm3, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm3, \n",
    "            alpha=.5, color=\"darkturquoise\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(6, 1, figsize=(8,22), sharey=True)\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.subplot(6,1,1)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm, 1)\n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regession')\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(6,1,2)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"teal\", s=100, label=\"Model: TweedieRegressor\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_glm, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: TweedieRegressor')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(6,1,3)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm2, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model 2nd degree Polynomial')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(5,1,3)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm3, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model 3rd degree Polynomial\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm3, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model 2nd degree Polynomial')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(6,1,4)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lars, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: Lasso')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(6,1,5)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lars, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: Lasso')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(6,1,6)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"teal\", s=100, label=\"Model: TweedieRegressor\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm2, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.title('All Models stacked')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 2))\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_medium, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_medium, 2))\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train_lm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train_lars, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lars)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train_glm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_glm)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm2, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm2)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train_lm3, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
